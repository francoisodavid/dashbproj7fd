{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce07437a",
   "metadata": {},
   "source": [
    "# Prediction d'éligibilité à un crédit\n",
    "## Partie Modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53f92c2",
   "metadata": {},
   "source": [
    "On a deux options pour les données sur lesquelles on fait tourner le modèle :\n",
    "    On le fait : \\\n",
    "    - soit sur mon feature engineering : dans ce cas on commente la ligne df = main() \\\n",
    "    - soit sur un feature engineering issu de kaggle dans ce cas on laisse df=main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29d70c3",
   "metadata": {},
   "source": [
    "####  Chargement de fonctions standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c784b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from srfunctions import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc8a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c508a3",
   "metadata": {},
   "source": [
    "#### Chargement de fonctions spécifiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d5be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a02c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "print(imblearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064af353",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d07bae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f6cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7be401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1875d3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import itertools\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a811bf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from lime import lime_tabular\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a76f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm_notebook\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import time\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0550e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344f8a81",
   "metadata": {},
   "source": [
    "#### Chargement du df issu de mon Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e4e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanpath = \"data\\\\cleaned\\\\\"\n",
    "apptrain=pd.read_csv(cleanpath+\"ApptrainSaved1.csv\")\n",
    "apptrain.head()\n",
    "print(apptrain.shape)\n",
    "df=apptrain.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0713b61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "apptrain.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71db72c",
   "metadata": {},
   "source": [
    "#### Ou bien recalcul d'un feature engineering amélioré venant de Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3415c56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "\n",
    "# One-hot encoding for categorical columns with get_dummies\n",
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns\n",
    "\n",
    "# Preprocess application_train.csv and application_test.csv\n",
    "def application_train_test(num_rows = None, nan_as_category = False):\n",
    "    # Read data and merge\n",
    "    df = pd.read_csv('data\\\\source\\\\application_train.csv', nrows= num_rows)\n",
    "    test_df = pd.read_csv('data\\\\source\\\\application_test.csv', nrows= num_rows)\n",
    "    print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n",
    "    df = df.append(test_df).reset_index()\n",
    "    # Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']\n",
    "    \n",
    "    # Categorical features with Binary encode (0 or 1; two categories)\n",
    "    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "    # Categorical features with One-Hot encode\n",
    "    df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
    "    \n",
    "    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "    # Some simple new features (percentages)\n",
    "    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "    del test_df\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "# Preprocess bureau.csv and bureau_balance.csv\n",
    "def bureau_and_balance(num_rows = None, nan_as_category = True):\n",
    "    bureau = pd.read_csv('data\\\\source\\\\bureau.csv', nrows = num_rows)\n",
    "    bb = pd.read_csv('data\\\\source\\\\bureau_balance.csv', nrows = num_rows)\n",
    "    bb, bb_cat = one_hot_encoder(bb, nan_as_category)\n",
    "    bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n",
    "    \n",
    "    # Bureau balance: Perform aggregations and merge with bureau.csv\n",
    "    bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
    "    for col in bb_cat:\n",
    "        bb_aggregations[col] = ['mean']\n",
    "    bb_agg = bb.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n",
    "    bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "    bureau = bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "    bureau.drop(['SK_ID_BUREAU'], axis=1, inplace= True)\n",
    "    del bb, bb_agg\n",
    "    gc.collect()\n",
    "    \n",
    "    # Bureau and bureau_balance numeric features\n",
    "    num_aggregations = {\n",
    "        'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "        'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "        'DAYS_CREDIT_UPDATE': ['mean'],\n",
    "        'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "        'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
    "        'AMT_ANNUITY': ['max', 'mean'],\n",
    "        'CNT_CREDIT_PROLONG': ['sum'],\n",
    "        'MONTHS_BALANCE_MIN': ['min'],\n",
    "        'MONTHS_BALANCE_MAX': ['max'],\n",
    "        'MONTHS_BALANCE_SIZE': ['mean', 'sum']\n",
    "    }\n",
    "    # Bureau and bureau_balance categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in bureau_cat: cat_aggregations[cat] = ['mean']\n",
    "    for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = ['mean']\n",
    "    \n",
    "    bureau_agg = bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "    # Bureau: Active credits - using only numerical aggregations\n",
    "    active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
    "    active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n",
    "    del active, active_agg\n",
    "    gc.collect()\n",
    "    # Bureau: Closed credits - using only numerical aggregations\n",
    "    closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
    "    closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n",
    "    del closed, closed_agg, bureau\n",
    "    gc.collect()\n",
    "    return bureau_agg\n",
    "\n",
    "# Preprocess previous_applications.csv\n",
    "def previous_applications(num_rows = None, nan_as_category = True):\n",
    "    prev = pd.read_csv('data\\source\\previous_application.csv', nrows = num_rows)\n",
    "    prev, cat_cols = one_hot_encoder(prev, nan_as_category= True)\n",
    "    # Days 365.243 values -> nan\n",
    "    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
    "    # Add feature: value ask / value received percentage\n",
    "    prev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
    "    # Previous applications numeric features\n",
    "    num_aggregations = {\n",
    "        'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "        'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "        'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "        'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "        'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
    "        'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "        'CNT_PAYMENT': ['mean', 'sum'],\n",
    "    }\n",
    "    # Previous applications categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in cat_cols:\n",
    "        cat_aggregations[cat] = ['mean']\n",
    "    \n",
    "    prev_agg = prev.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "    # Previous Applications: Approved Applications - only numerical features\n",
    "    approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "    approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
    "    # Previous Applications: Refused Applications - only numerical features\n",
    "    refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "    refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n",
    "    del refused, refused_agg, approved, approved_agg, prev\n",
    "    gc.collect()\n",
    "    return prev_agg\n",
    "\n",
    "# Preprocess POS_CASH_balance.csv\n",
    "def pos_cash(num_rows = None, nan_as_category = True):\n",
    "    pos = pd.read_csv('data\\source\\POS_CASH_balance.csv', nrows = num_rows)\n",
    "    pos, cat_cols = one_hot_encoder(pos, nan_as_category= True)\n",
    "    # Features\n",
    "    aggregations = {\n",
    "        'MONTHS_BALANCE': ['max', 'mean', 'size'],\n",
    "        'SK_DPD': ['max', 'mean'],\n",
    "        'SK_DPD_DEF': ['max', 'mean']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    \n",
    "    pos_agg = pos.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "    # Count pos cash accounts\n",
    "    pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n",
    "    del pos\n",
    "    gc.collect()\n",
    "    return pos_agg\n",
    "    \n",
    "# Preprocess installments_payments.csv\n",
    "def installments_payments(num_rows = None, nan_as_category = True):\n",
    "    ins = pd.read_csv('data\\source\\installments_payments.csv', nrows = num_rows)\n",
    "    ins, cat_cols = one_hot_encoder(ins, nan_as_category= True)\n",
    "    # Percentage and difference paid in each installment (amount paid and installment value)\n",
    "    ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
    "    ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
    "    # Days past due and days before due (no negative values)\n",
    "    ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
    "    ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
    "    ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "    ins['DBD'] = ins['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "    # Features: Perform aggregations\n",
    "    aggregations = {\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "        'DPD': ['max', 'mean', 'sum'],\n",
    "        'DBD': ['max', 'mean', 'sum'],\n",
    "        'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n",
    "        'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n",
    "        'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
    "        'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "        'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    ins_agg.columns = pd.Index(['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "    # Count installments accounts\n",
    "    ins_agg['INSTAL_COUNT'] = ins.groupby('SK_ID_CURR').size()\n",
    "    del ins\n",
    "    gc.collect()\n",
    "    return ins_agg\n",
    "\n",
    "# Preprocess credit_card_balance.csv\n",
    "def credit_card_balance(num_rows = None, nan_as_category = True):\n",
    "    cc = pd.read_csv('data\\\\source\\\\credit_card_balance.csv', nrows = num_rows)\n",
    "    cc, cat_cols = one_hot_encoder(cc, nan_as_category= True)\n",
    "    # General aggregations\n",
    "    cc.drop(['SK_ID_PREV'], axis= 1, inplace = True)\n",
    "    cc_agg = cc.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
    "    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "    # Count credit card lines\n",
    "    cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n",
    "    del cc\n",
    "    gc.collect()\n",
    "    return cc_agg\n",
    "\n",
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lgbm_importances01.png')\n",
    "\n",
    "\n",
    "def main(debug = False):\n",
    "    num_rows = 10000 if debug else None\n",
    "    df = application_train_test(num_rows)\n",
    "    with timer(\"Process bureau and bureau_balance\"):\n",
    "        bureau = bureau_and_balance(num_rows)\n",
    "        print(\"Bureau df shape:\", bureau.shape)\n",
    "        df = df.join(bureau, how='left', on='SK_ID_CURR')\n",
    "        del bureau\n",
    "        gc.collect()\n",
    "        print(df.shape)\n",
    "    with timer(\"Process previous_applications\"):\n",
    "        prev = previous_applications(num_rows)\n",
    "        print(\"Previous applications df shape:\", prev.shape)\n",
    "        df = df.join(prev, how='left', on='SK_ID_CURR')\n",
    "        del prev\n",
    "        gc.collect()\n",
    "        print(df.shape)\n",
    "    with timer(\"Process POS-CASH balance\"):\n",
    "        pos = pos_cash(num_rows)\n",
    "        print(\"Pos-cash balance df shape:\", pos.shape)\n",
    "        df = df.join(pos, how='left', on='SK_ID_CURR')\n",
    "        del pos\n",
    "        print(df.shape)\n",
    "        gc.collect()\n",
    "        print(df.shape)\n",
    "    with timer(\"Process installments payments\"):\n",
    "        ins = installments_payments(num_rows)\n",
    "        print(\"Installments payments df shape:\", ins.shape)\n",
    "        df = df.join(ins, how='left', on='SK_ID_CURR')\n",
    "        del ins\n",
    "        print(df.shape)\n",
    "        gc.collect()\n",
    "        print(df.shape)\n",
    "    with timer(\"Process credit card balance\"):\n",
    "        cc = credit_card_balance(num_rows)\n",
    "        print(\"Credit card balance df shape:\", cc.shape)\n",
    "        df = df.join(cc, how='left', on='SK_ID_CURR')\n",
    "        del cc\n",
    "        print(df.shape)\n",
    "        gc.collect()\n",
    "        print(df.shape)\n",
    "    #with timer(\"Run LightGBM with kfold\"):\n",
    "    #    feat_importance = kfold_lightgbm(df, num_folds= 10, stratified= False, debug= debug)\n",
    "    return df\n",
    "#if __name__ == \"__main__\":\n",
    "#    #submission_file_name = \"submission_kernel02.csv\"\n",
    "#    with timer(\"Full model run\"):\n",
    "#        df=main()\n",
    "#        print(df.shape)\n",
    "#        return df\n",
    "df=main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aa7ff6",
   "metadata": {},
   "source": [
    "#### Downsampling du df pour la tractabilité de la classification qui peut prendre du temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dfe922",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=0.5)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ee0589",
   "metadata": {},
   "source": [
    "#### Passage de l'ID client en index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60e69ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.columns.isin(['SK_ID_CURR']).sum()==1 :\n",
    "    print('YES')\n",
    "    df.set_index('SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f2a427",
   "metadata": {},
   "source": [
    "#### Drope de la colonne index \n",
    "pas pertinente pour la classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b415a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.columns.isin(['index']).sum()==1 :\n",
    "    df.drop('index',axis=1,inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ba0066",
   "metadata": {},
   "source": [
    "#### On enleve les lignes si la TARGET n'est pas renseignée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2a056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df[\"TARGET\"].isna()].index,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cf1004",
   "metadata": {},
   "source": [
    "#### On traite/formatte les valeurs infinies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b6d810",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace((np.inf, -np.inf, np.NaN), np.nan).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf67b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('min max indice client',df.SK_ID_CURR.min(),df.SK_ID_CURR.max())  # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48caa337",
   "metadata": {},
   "source": [
    "# Partie commune à tous les modèles\n",
    "#### Séparation de la target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4994a737",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(df.drop(columns=['TARGET','SK_ID_CURR']))\n",
    "Y_train=np.array(df['TARGET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dbb175",
   "metadata": {},
   "source": [
    "#### Option de Shuffling des index pour éviter une éventuelle organisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d158bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p=np.arange(Y_train.shape[0])\n",
    "#np.random.shuffle(p)\n",
    "#len(p)\n",
    "#p[np.int(0.8*len(p)):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15275381",
   "metadata": {},
   "source": [
    "### Création du jeu de test pour l'évaluation\n",
    "### Partition qu'on initie une seule fois pour tous les modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d876364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation d'un jeu de validation\n",
    "X_TRAIN, X_VALID, Y_TRAIN, Y_VALID = train_test_split(X_train, Y_train, test_size=0.2, stratify=Y_train, random_state=42)\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mean.fit(X_TRAIN)\n",
    "X_TRAIN=imp_mean.transform(X_TRAIN)\n",
    "imp_mean.fit(X_VALID)\n",
    "X_VALID=imp_mean.transform(X_VALID)\n",
    "print(X_TRAIN.shape,Y_TRAIN.shape,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbd867f",
   "metadata": {},
   "source": [
    "### Création d'un dummy model : valeur constante la plus frequente de la prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beb9c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_TRAIN\n",
    "y = Y_TRAIN\n",
    "dummy_clf = DummyClassifier(strategy=\"constant\",constant=0) #DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf.fit(X_TRAIN, Y_TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b0cc0a",
   "metadata": {},
   "source": [
    "#### Calcul du score auroc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566bb951",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=dummy_clf.predict(X_VALID)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Y_VALID, pred, pos_label=2)\n",
    "print(fpr, tpr, thresholds)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478467cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(Y_VALID, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8afbcb4",
   "metadata": {},
   "source": [
    "#### Représentation des matrices de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745a183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=confusion_matrix(Y_VALID,pred)\n",
    "c=c/c.astype(np.float).sum(axis=0)\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(c, annot=True, fmt='.2f')#, xticklabels=['0','1'], yticklabels==['0','1'])\n",
    "plt.ylabel('Réel')\n",
    "plt.xlabel('Prédit')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087ec2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(dummy_clf, X_VALID, Y_VALID)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dcc11d",
   "metadata": {},
   "source": [
    "## Test de 5 modèles :  RandomForestClassifier, LogisticRegression, LGBM, XGBoost, CATBoost\n",
    "### avec GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5616164",
   "metadata": {},
   "source": [
    "## 1 RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e269cdd",
   "metadata": {},
   "source": [
    "#### Creation d'un jeu de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cea037",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN, X_VALID, Y_TRAIN, Y_VALID = train_test_split(X_train, Y_train, test_size=0.2, stratify=Y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad24e218",
   "metadata": {},
   "source": [
    "#### Boucle sur toutes les combinaisons d'hyperparamètres possibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dd7638",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "parameters = { \n",
    "    'n_estimators': [150,200],\n",
    "    'max_features': ['log2','sqrt'],#, 'log2'],\n",
    "    'criterion' :['gini', 'entropy'],\n",
    "    'max_depth' :[5,8],\n",
    "    'min_samples_leaf' :[5,10]\n",
    "}\n",
    "\n",
    "keys = parameters.keys()\n",
    "values = (parameters[key] for key in keys)\n",
    "combinations = [dict(zip(keys, combination)) for combination in itertools.product(*values)]\n",
    "\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mean.fit(X_TRAIN) # imputer\n",
    "X_TRAIN=imp_mean.transform(X_TRAIN)\n",
    "X_VALID=imp_mean.transform(X_VALID)\n",
    "\n",
    "# creation d'une boucle de cross-validation\n",
    "\n",
    "score=np.empty((len(combinations),5))\n",
    "score_combi=np.empty((len(combinations),1))\n",
    "\n",
    "print(\"all combinations of hyperparameters=\",combinations)\n",
    "n_cv=4\n",
    "n=0\n",
    "#for combination in tqdm(combinations):\n",
    "for combination in tqdm_notebook(combinations):    \n",
    "    print(combination)\n",
    "    kf = KFold(n_splits=n_cv)\n",
    "    i=0\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_TRAIN):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        x_train, x_test = X_TRAIN[train_index], X_TRAIN[test_index]\n",
    "        y_train, y_test = Y_TRAIN[train_index], Y_TRAIN[test_index]\n",
    "        #for i in range(n_cv): # iter on CV trains\n",
    "        # creation d'un jeu de test\n",
    "        #x_train, x_test, y_train, y_test = train_test_split(X_TRAIN, Y_TRAIN, test_size=0.2, random_state=i)\n",
    "        counter = Counter(y_train) # print(counter)\n",
    "        \n",
    "        rf_clf = RandomForestClassifier(n_estimators=combination[\"n_estimators\"],max_features=combination[\"max_features\"],\n",
    "                                        criterion=combination[\"criterion\"],max_depth=combination[\"max_depth\"] , min_samples_leaf=combination[\"min_samples_leaf\"] ,class_weight='balanced')\n",
    "        rf_clf.fit(x_train, y_train)\n",
    "        pred=rf_clf.predict(x_train) \n",
    "        #print('scoretrain:',roc_auc_score(y_train, pred))\n",
    "\n",
    "        #imp_mean.fit(x_test) # imputer\n",
    "        #x_test=imp_mean.transform(x_test) \n",
    "        pred=rf_clf.predict(x_test)\n",
    "        print('scoretest:',roc_auc_score(y_test, pred))\n",
    "        print(n)\n",
    "        score[n,i]=roc_auc_score(y_test, pred)\n",
    "        i=i+1\n",
    "    score_combi[n,0:1]=score[n,0:n_cv].mean()\n",
    "    print(\"score_combi\",score_combi[n])\n",
    "    n=n+1\n",
    "\n",
    "print(np.argmax(score_combi))\n",
    "bestparameters=combinations[np.argmax(score_combi)]\n",
    "print('bestparam:',bestparameters)    \n",
    "\n",
    "# une fois le modèle choisi et ses 'bestparameters' sauvés\n",
    "# on entraine ce modèle sur le jeu complet, pour le rendre plus robuste\n",
    "# cela évite de devoir choisir un modèles entrainés sur des jeux de données partiels\n",
    "# et permet aussi plus de robustesse\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=bestparameters[\"n_estimators\"],max_features=bestparameters[\"max_features\"],\n",
    "                                criterion=bestparameters[\"criterion\"], max_depth=bestparameters[\"max_depth\"] , min_samples_leaf=bestparameters[\"min_samples_leaf\"], class_weight='balanced')\n",
    "rf_clf = rf_clf.fit(X_TRAIN, Y_TRAIN)\n",
    "pred = rf_clf.predict(X_VALID)\n",
    "print(roc_auc_score(Y_VALID, pred))\n",
    "####score[n]=roc_auc_score(Y_TEST, pred)\n",
    "\n",
    "# on sauve le meilleur modele entrainé\n",
    "filename = 'model_rf_clf' + '.sav'\n",
    "joblib.dump(rf_clf, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345814be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(X_TRAIN.shape)\n",
    "print(Y_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a1f915",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BESTMODEL='model_' + str(np.argmax(score_combi)) + '.sav'\n",
    "# load the model from disk\n",
    "BESTMODEL='model_rf_clf.sav'\n",
    "\n",
    "loaded_model = joblib.load(BESTMODEL)\n",
    "\n",
    "pred=loaded_model.predict(X_VALID)\n",
    "print(roc_auc_score(Y_VALID, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1b1063",
   "metadata": {},
   "source": [
    "### Represenation des résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac7a364",
   "metadata": {},
   "source": [
    "#### matrice de confusion avec les proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecf01c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=confusion_matrix(Y_VALID,pred)\n",
    "c=c/c.astype(np.float).sum(axis=0)\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "res=sns.heatmap(c, annot=True, fmt='.2f')#, xticklabels=['0','1'], yticklabels==['0','1'])\n",
    "plt.ylabel('Réel',fontsize=28)\n",
    "plt.xlabel('Prédit',fontsize=28)\n",
    "#plt.title('Correlation Heatmap',fontsize=28);\n",
    "res.set_xticklabels(res.get_xmajorticklabels(), rotation=0, horizontalalignment='right',fontsize = 18)\n",
    "res.set_yticklabels(res.get_ymajorticklabels(), rotation=0, horizontalalignment='right',fontsize = 18)\n",
    "res.tick_params(labelsize=28)\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed287be",
   "metadata": {},
   "source": [
    "#### matrice de confusion avec les nombres absolus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08467ea0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res=plot_confusion_matrix(loaded_model, X_VALID, Y_VALID) \n",
    "plt.ylabel('Réel',fontsize=28)\n",
    "plt.xlabel('Prédit',fontsize=28)\n",
    "plt.xticks(fontsize=28)\n",
    "plt.yticks(fontsize=28)\n",
    "    \n",
    "\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cd080e",
   "metadata": {},
   "source": [
    "### Explication du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742bb3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_tabular.LimeTabularExplainer(X_TRAIN, mode=\"classification\",\n",
    "                                              class_names= df.TARGET.unique(),\n",
    "                                              feature_names= df.columns.drop(['TARGET']),\n",
    "                                             )\n",
    "\n",
    "explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f1e818",
   "metadata": {},
   "source": [
    "#### on choisit plusieurs cas particuliers à expliquer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ec2a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = random.randint(1, len(X_VALID))\n",
    "\n",
    "BESTMODEL='model_rf_clf.sav'\n",
    "loaded_model = joblib.load(BESTMODEL)\n",
    "\n",
    "pred=loaded_model.predict(X_VALID)\n",
    "\n",
    "idx = random.randint(1, len(X_VALID))\n",
    "\n",
    "print(\"Prediction : \", loaded_model.predict(X_VALID[idx].reshape(1,-1)))\n",
    "print(\"Actual :     \", Y_VALID[idx])\n",
    "\n",
    "#print(\"Prediction : \", breast_cancer.target_names[lr.predict(X_VALID[idx].reshape(1,-1))[0]])\n",
    "#print(\"Actual :     \", breast_cancer.target_names[Y_VALID[idx]])\n",
    "\n",
    "explanation = explainer.explain_instance(X_VALID[idx], loaded_model.predict_proba,\n",
    "                                         num_features=len(df.columns)-1) # je mets moins 1 pour enlever la target qui n'est pas une feature\n",
    "\n",
    "explanation.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d5d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = loaded_model.predict(X_VALID)\n",
    "target_preds = np.argwhere(((preds == Y_VALID) & (preds == 0))).flatten()\n",
    "idx  = random.choice(target_preds)\n",
    "\n",
    "#BESTMODEL='model_rf_clf.sav'\n",
    "#loaded_model = joblib.load(BESTMODEL)\n",
    "\n",
    "#pred=loaded_model.predict(X_VALID)\n",
    "\n",
    "#idx = random.randint(1, len(X_VALID))\n",
    "\n",
    "print(\"Prediction : \", loaded_model.predict(X_VALID[idx].reshape(1,-1)))\n",
    "print(\"Actual :     \", Y_VALID[idx])\n",
    "\n",
    "#print(\"Prediction : \", breast_cancer.target_names[lr.predict(X_VALID[idx].reshape(1,-1))[0]])\n",
    "#print(\"Actual :     \", breast_cancer.target_names[Y_VALID[idx]])\n",
    "\n",
    "explanation = explainer.explain_instance(X_VALID[idx], loaded_model.predict_proba,\n",
    "                                         num_features=len(df.columns)-1) # je mets moins 1 pour enlever la target qui n'est pas une feature\n",
    "\n",
    "explanation.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ebfada",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = loaded_model.predict(X_VALID)\n",
    "target_preds = np.argwhere(((preds == Y_VALID) & (preds == 1))).flatten()\n",
    "idx  = random.choice(target_preds)\n",
    "\n",
    "#BESTMODEL='model_rf_clf.sav'\n",
    "#loaded_model = joblib.load(BESTMODEL)\n",
    "\n",
    "pred=loaded_model.predict(X_VALID)\n",
    "\n",
    "#idx = random.randint(1, len(X_VALID))\n",
    "\n",
    "print(\"Prediction : \", loaded_model.predict(X_VALID[idx].reshape(1,-1)))\n",
    "print(\"Actual :     \", Y_VALID[idx])\n",
    "\n",
    "#print(\"Prediction : \", breast_cancer.target_names[lr.predict(X_VALID[idx].reshape(1,-1))[0]])\n",
    "#print(\"Actual :     \", breast_cancer.target_names[Y_VALID[idx]])\n",
    "\n",
    "explanation = explainer.explain_instance(X_VALID[idx], loaded_model.predict_proba,\n",
    "                                         num_features=len(df.columns)-1) # je mets moins 1 pour enlever la target qui n'est pas une feature\n",
    "\n",
    "explanation.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa3fc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation.as_list()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561493d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df.columns))\n",
    "print(np.shape(X_VALID))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d792b1",
   "metadata": {},
   "source": [
    "#### Explication globale avec shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7267494",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "explainer=shap.TreeExplainer(loaded_model)#rf_clf)\n",
    "values=explainer.shap_values(X_TRAIN)\n",
    "#shap.plots.waterfall(values)#beeswarm(values[0])#waterfall(values[0]) # shap.plots.beeswarm(values[0])#waterfall(values[0])\n",
    "listfeat=df.columns.drop(['TARGET','SK_ID_CURR'])\n",
    "shap.summary_plot(values,X_TRAIN, feature_names = listfeat)#.drop(['TARGET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c125bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SK_ID_CURR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c81510",
   "metadata": {},
   "source": [
    "#### Extraction des features avec le plus d'importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c75ba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals= np.abs(values).mean(0)\n",
    "feature_importance = pd.DataFrame(list(zip(listfeat,vals)),columns=['col_name','feature_importance_vals'])\n",
    "feature_importance['importance_mean']=feature_importance.feature_importance_vals.mean()\n",
    "feature_importance.sort_values(by=['importance_mean'],ascending=False,inplace=True)\n",
    "feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33c7f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5e6327",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.DAYS_BIRTH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ca52a7",
   "metadata": {},
   "source": [
    "# Application de la meme grid search manuelle pour Lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ca73c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(df.drop(columns=['TARGET','SK_ID_CURR']))\n",
    "Y_train=np.array(df['TARGET'])\n",
    "X_TRAIN, X_VALID, Y_TRAIN, Y_VALID = train_test_split(X_train, Y_train, test_size=0.2, stratify=Y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58d4380",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "parameters = {'learning_rate': [0.09, 0.1, 0.11, 0.12],# 0.01],\n",
    "    'n_estimators': [64, 76, 96, 110, 120],\n",
    "    'num_leaves': [8, 9, 10, 11, 12],} # large num_leaves helps improve accuracy but might lead to over-fitting}\n",
    "keys = parameters.keys()\n",
    "values = (parameters[key] for key in keys)\n",
    "combinations = [dict(zip(keys, combination)) for combination in itertools.product(*values)]\n",
    "\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mean.fit(X_TRAIN) # imputer\n",
    "X_TRAIN=imp_mean.transform(X_TRAIN)\n",
    "X_VALID=imp_mean.transform(X_VALID)\n",
    "\n",
    "# creation d'une boucle de cross-validation\n",
    "\n",
    "score=np.empty((len(combinations),5)) # matrix de score cv\n",
    "score_combi=np.empty((len(combinations),1)) # matrice de score grid\n",
    "\n",
    "print(\"all combinations of hyperparameters=\",combinations)\n",
    "n_cv=2\n",
    "n=0\n",
    "for combination in tqdm_notebook(combinations):    \n",
    "    print(combination)\n",
    "    kf = KFold(n_splits=n_cv)\n",
    "    i=0\n",
    "    for train_index, test_index in kf.split(X_TRAIN):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        x_train, x_test = X_TRAIN[train_index], X_TRAIN[test_index]\n",
    "        y_train, y_test = Y_TRAIN[train_index], Y_TRAIN[test_index]\n",
    "        \n",
    "        LightGBM_clf=lgb.LGBMClassifier(learning_rate=combination[\"learning_rate\"],n_estimators=combination[\"n_estimators\"],num_leaves=combination[\"num_leaves\"], class_weight='balanced')#,scale_pos_weight=scale_pos_weight_value)\n",
    "        LightGBM_clf.fit(x_train, y_train)\n",
    "        pred=LightGBM_clf.predict(x_train)\n",
    "        \n",
    "        #print('scoretrain:',roc_auc_score(y_train, pred))\n",
    "        pred=LightGBM_clf.predict(x_test)\n",
    "        print('scoretest:',roc_auc_score(y_test, pred))\n",
    "        print(n)\n",
    "        score[n,i]=roc_auc_score(y_test, pred)\n",
    "        i=i+1\n",
    "    score_combi[n,0:1]=score[n,0:n_cv].mean()\n",
    "    print(\"score_combi\",score_combi[n])\n",
    "    n=n+1\n",
    "print(np.argmax(score_combi))\n",
    "bestparameters=combinations[np.argmax(score_combi)]\n",
    "print('bestparam:',bestparameters)    \n",
    "\n",
    "# on recupere les hypermarametres et on reentraine le modele avec tout le jeu de données\n",
    "lgb_clf = lgb.LGBMClassifier(random_state = 0, learning_rate=bestparameters[\"learning_rate\"] , \n",
    "                                    n_estimators=bestparameters[\"n_estimators\"], num_leaves=bestparameters[\"num_leaves\"], class_weight='balanced')\n",
    "lgb_clf = lgb_clf.fit(X_TRAIN, Y_TRAIN)\n",
    "# on applique le modele au set de validation\n",
    "pred=lgb_clf.predict(X_VALID)\n",
    "print(roc_auc_score(Y_VALID, pred))\n",
    "\n",
    "# on sauve le meilleur modele entrainé\n",
    "filename = 'model_lgb_clf' + '.sav'\n",
    "joblib.dump(lgb_clf, filename)\n",
    "##############\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9840565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "BESTMODEL='model_lgb_clf.sav'\n",
    "\n",
    "loaded_model = joblib.load(BESTMODEL)\n",
    "\n",
    "pred=loaded_model.predict(X_VALID)\n",
    "print(roc_auc_score(Y_VALID, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70817e2d",
   "metadata": {},
   "source": [
    "## Représentation des résultats "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a904b716",
   "metadata": {},
   "source": [
    "#### matrice de confusion avec proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fac74b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c=confusion_matrix(Y_VALID,pred)\n",
    "c=c/c.astype(np.float).sum(axis=0)\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(c, annot=True, fmt='.2f')#, xticklabels=['0','1'], yticklabels==['0','1'])\n",
    "plt.ylabel('Réel')\n",
    "plt.xlabel('Prédit')\n",
    "plt.show(block=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c62938",
   "metadata": {},
   "source": [
    "#### mat de confusion avec nombres absolus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e359a89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(loaded_model, X_VALID, Y_VALID)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7373391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BESTMODEL='model_lgb_clf.sav'\n",
    "loaded_model = joblib.load(BESTMODEL)\n",
    "\n",
    "pred=loaded_model.predict(X_VALID)\n",
    "\n",
    "idx = random.randint(1, len(X_VALID))\n",
    "\n",
    "print(\"Prediction : \", loaded_model.predict(X_VALID[idx].reshape(1,-1)))\n",
    "print(\"Actual :     \", Y_VALID[idx])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b055376c",
   "metadata": {},
   "source": [
    "#### on fait un simple imputer car Shap n'accepte pas les Nan contrainement à lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24989ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN, X_VALID, Y_TRAIN, Y_VALID = train_test_split(X_train, Y_train, test_size=0.2, stratify=Y_train, random_state=42)\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mean.fit(X_TRAIN) # imputer\n",
    "X_TRAIN=imp_mean.transform(X_TRAIN)\n",
    "X_VALID=imp_mean.transform(X_VALID) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a2f89f",
   "metadata": {},
   "source": [
    "#### extraction des paraètres globaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b642c6a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#BESTMODEL='model_lgb_clf.sav'\n",
    "#loaded_model = joblib.load(BESTMODEL)\n",
    "#loaded_model.fit(X_TRAIN, Y_TRAIN)\n",
    "explainer=shap.TreeExplainer(lgb_clf)\n",
    "values=explainer.shap_values(X_TRAIN)\n",
    "#shap.plots.waterfall(values)#beeswarm(values[0])#waterfall(values[0])\n",
    "listfeat=df.columns.drop(['TARGET','SK_ID_CURR'])\n",
    "shap.summary_plot(values,X_TRAIN, feature_names = listfeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cdddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals= np.abs(values).mean(0).mean(0)\n",
    "feature_importance = pd.DataFrame(list(zip(listfeat,vals)),columns=['col_name','feature_importance_vals'])\n",
    "feature_importance.sort_values(by=['feature_importance_vals'],ascending=False,inplace=True)\n",
    "feature_importance.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e2d50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1/0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11a6c81",
   "metadata": {},
   "source": [
    "# Realisation d'un modèle simplifié pour la mise en production\n",
    "#### Stratégie : on réentraine le modèle sur les n=100 features les plus importantes pour alléger et rationaliser la modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fcf881",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# on sauve un df simplifié avec les features qui ont la plus grande importance\n",
    "df1=df[list(feature_importance.head(100).col_name.values)+list(['TARGET','SK_ID_CURR'])] # on rajoute la TARGET et l'ID client\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cb3de7",
   "metadata": {},
   "source": [
    "#### on réentraine le modèle avec les mêmes paramètres et on le sauve pour l'utilisaiton par streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdacea3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train=np.array(df1.drop(columns=['TARGET','SK_ID_CURR']))\n",
    "Y_train=np.array(df1['TARGET'])\n",
    "X_TRAIN, X_VALID, Y_TRAIN, Y_VALID = train_test_split(X_train, Y_train, test_size=0.2, stratify=Y_train, random_state=42)\n",
    "\n",
    "\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mean.fit(X_TRAIN) # imputer\n",
    "X_TRAIN=imp_mean.transform(X_TRAIN)\n",
    "X_VALID=imp_mean.transform(X_VALID)\n",
    "\n",
    "# creation d'une boucle de cross-validation\n",
    "\n",
    "\n",
    "# on recupere les hypermarametres et on reentraine le modele avec tout le jeu de données\n",
    "lgb_clf = lgb.LGBMClassifier(random_state = 0, learning_rate=bestparameters[\"learning_rate\"] , \n",
    "                                    n_estimators=bestparameters[\"n_estimators\"], num_leaves=bestparameters[\"num_leaves\"], class_weight='balanced')\n",
    "lgb_clf = lgb_clf.fit(X_TRAIN, Y_TRAIN)\n",
    "# on applique le modele au set de validation\n",
    "pred=lgb_clf.predict(X_VALID)\n",
    "print(roc_auc_score(Y_VALID, pred))\n",
    "\n",
    "# on sauve le meilleur modele entrainé\n",
    "filename = 'defaultcredit-fd/fdboard/model/model_lgb_clf_light' + '.sav'\n",
    "joblib.dump(lgb_clf, filename)\n",
    "##############"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425780ee",
   "metadata": {},
   "source": [
    "Logiquement le score reste bon en enlevant les features ayant peu d'importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b019e2e",
   "metadata": {},
   "source": [
    "#### on reloade le modele pour verifier que tout fonctionne bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0295ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "BESTMODEL='defaultcredit-fd/fdboard/model/model_lgb_clf_light.sav'\n",
    "\n",
    "loaded_model = joblib.load(BESTMODEL)\n",
    "\n",
    "pred=loaded_model.predict(X_VALID)\n",
    "print(roc_auc_score(Y_VALID, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01f1551",
   "metadata": {},
   "source": [
    "application à un exemple d'un client - permet de verifier si tout fonctionne correctement en vue du dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be15b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.randint(5,30,size=1)\n",
    "seed[0]\n",
    "\n",
    "print('REAL TARGET : ',df1.sample(1,random_state=seed[0]).TARGET)\n",
    "\n",
    "pred=lgb_clf.predict(df1.sample(1,random_state=seed[0]).drop(columns=['TARGET','SK_ID_CURR']).values)\n",
    "print(lgb_clf.predict_proba(df1.sample(1,random_state=seed[0]).drop(columns=['TARGET','SK_ID_CURR']).values)[:,1])\n",
    "print('PREDICTED TARGET : ',pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3564e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# je sauve mes prédictions sur tout le df\n",
    "X_df=df1.copy()\n",
    "X_df.drop(columns=['TARGET','SK_ID_CURR'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b273c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['PRED']=lgb_clf.predict(df1.drop(columns=['TARGET','SK_ID_CURR']).values)\n",
    "\n",
    "df1['PREDproba']=lgb_clf.predict_proba(X_df.values)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5b88f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clf.predict_proba(X_df.values)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0085f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clf.predict(X_df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d415e4a7",
   "metadata": {},
   "source": [
    "#### on fait un KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb48709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from yellowbrick.cluster import KElbowVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1cead3",
   "metadata": {},
   "source": [
    "##### on est obligé de faire un imputer car les données NaN ne sont pas acceptées par le KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189bb1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "X = df1.copy()\n",
    "imp_mean.fit(X)\n",
    "X=imp_mean.transform(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db44ddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans()\n",
    "visualizer = KElbowVisualizer(model, k=(4,12))\n",
    "visualizer.fit(X)\n",
    "visualizer.poof() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049d98ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "kcluster=visualizer.elbow_value_\n",
    "kcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76f2910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run local implementation of kmeans\n",
    "model = KMeans(n_clusters=kcluster, random_state=40)\n",
    "model.fit(X)\n",
    "#centroids = model.cluster_centers_\n",
    "#centroids\n",
    "# Plot the clustered data\n",
    "df1[\"cluster\"]=model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e98949",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac72b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"cluster\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86841e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae8bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"bias\"]=10.0 #initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b77e4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# On reeachantillone la base pour avoir une représenation equiprobable des clusters\n",
    "for i in range(kcluster):\n",
    "    print(i)\n",
    "    val=float(df1[\"cluster\"].loc[df1.cluster==i].value_counts())\n",
    "    #print(1/val)\n",
    "    #print(df1[\"cluster\"].loc[df1.cluster==i].value_counts())\n",
    "    df1.loc[df1['cluster'] ==i, 'bias']=1/val #df1[\"cluster\"].loc[df1.cluster==i].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c665b95",
   "metadata": {},
   "source": [
    "## on sauve une base plus PETITE (n=x) pour les représentations graphique du dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ff150b",
   "metadata": {},
   "source": [
    "Je sauve les valeurs réelles et les valeurs prédites de la Target , ça peut être utile dans le Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cbe946",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = df1[\"bias\"]\n",
    "df2=df1.sample(n=30, weights=bias )\n",
    "\n",
    "df2xl=df1.sample(n=4000, weights=bias )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84baadf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(columns=['bias'],inplace=True)\n",
    "df2xl.drop(columns=['bias'],inplace=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01cf3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe5aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"defaultcredit-fd/fdboard/df_for_prod.csv\",index=False)\n",
    "df2xl.to_csv(\"defaultcredit-fd/fdboard/dfXL_for_prod.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c98545f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095c25ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0707b84a",
   "metadata": {},
   "source": [
    "### Pour cette plus petite base on va sauver une explication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db840259",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc56113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_tabular.LimeTabularExplainer(X_TRAIN, mode=\"classification\",\n",
    "                                              class_names= df2.TARGET.unique(),\n",
    "                                              feature_names= df2.columns.drop(['TARGET','SK_ID_CURR','PRED','PREDproba','cluster']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e2df3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b02c7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_TRAIN.shape)\n",
    "print(len(df2.columns.drop(['TARGET','PRED','cluster'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5296e357",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.read_csv(\"defaultcredit-fd/fdboard/df_for_prod.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84658de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50e290e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2c24f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18704990",
   "metadata": {},
   "source": [
    "#### on genere des image pour un certain nombre de client pour l'appli en ligne\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848fbef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,idc in enumerate(df3.SK_ID_CURR.values):\n",
    "    print('i,idc:',i,idc)\n",
    "    print('pred,proba,target',df3.loc[df3.SK_ID_CURR==idc,['PRED','PREDproba','TARGET']].values)#,df3.loc[df3.SK_ID_CURR==idc,'PREDproba'].values,df3.loc[df3.SK_ID_CURR==idc,'TARGET'].values)\n",
    "    explanation = explainer.explain_instance(df2.iloc[i].drop(['TARGET','SK_ID_CURR','PRED','PREDproba','cluster']).values, loaded_model.predict_proba,labels=(1,),num_features=10)#len(df2.columns.drop(['TARGET','PRED','cluster'])))\n",
    "    figi=explanation.as_pyplot_figure()\n",
    "    plt.tight_layout()\n",
    "    #explanation.save_to_file('lime.html')\n",
    "    figname='defaultcredit-fd/fdboard/static/images/lime_'+str(idc)+'.png'\n",
    "    figi.savefig(figname)\n",
    "    #df3.loc[df3.index ==i, 'limage']=fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a212333d",
   "metadata": {},
   "source": [
    "#### de meme on genere une image shap pour le mise en prod (trop longue à calculer en ligne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eee42bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer=shap.TreeExplainer(lgb_clf)\n",
    "values=explainer.shap_values(X_TRAIN)\n",
    "#shap.plots.waterfall(values)#beeswarm(values[0])#waterfall(values[0])\n",
    "listfeat=df1.columns.drop(['TARGET','PRED','cluster','bias'])\n",
    "fig=plt.gcf()\n",
    "shap.summary_plot(values,X_TRAIN, feature_names = listfeat)\n",
    "figname='defaultcredit-fd/fdboard/static/images/imageshap.png'\n",
    "fig.savefig(figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1c9e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shap.plots.waterfall(explainer.shap_values[X_TRAIN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d3e8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.SK_ID_CURR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8befcea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if df3.columns.isin(['SK_ID_CURR']).sum()==1 :\n",
    "#    print('YES')\n",
    "#    df3.set_index('SK_ID_CURR',drop=True, inplace=True)\n",
    "df2 # on sauve pas cette version car les index sont resetté lors de la sauvegarde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ef656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.read_csv(\"defaultcredit-fd/fdboard/df_for_prod.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7446a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7970dfc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279bc592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11ae2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reprise de la reccherche d'un modele optimal avec d'autres méthodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae3e15e",
   "metadata": {},
   "source": [
    "### LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a04ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN, X_VALID, Y_TRAIN, Y_VALID = train_test_split(X_train, Y_train, test_size=0.2, stratify=Y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fc03e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameters = {'solver': ['newton-cg', 'lbfgs'],\n",
    "              'penalty': ['none', 'l2'],\n",
    "              'C': [0.01, 0.05]}\n",
    "\n",
    "keys = parameters.keys()\n",
    "values = (parameters[key] for key in keys)\n",
    "combinations = [dict(zip(keys, combination)) for combination in itertools.product(*values)]\n",
    "\n",
    "# creation d'une boucle de cross-validation\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mean.fit(X_TRAIN) # imputer\n",
    "X_TRAIN=imp_mean.transform(X_TRAIN)\n",
    "X_VALID=imp_mean.transform(X_VALID)\n",
    "\n",
    "score=np.empty((len(combinations),5)) # matrix de score cv\n",
    "score_combi=np.empty((len(combinations),1)) # matrice de score grid\n",
    "\n",
    "print(\"all combinations of hyperparameters=\",combinations)\n",
    "n_cv=2\n",
    "n=0\n",
    "\n",
    "for combination in tqdm_notebook(combinations):    \n",
    "    print(combination)\n",
    "    kf = KFold(n_splits=n_cv)\n",
    "    i=0\n",
    "    for train_index, test_index in kf.split(X_TRAIN):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        x_train, x_test = X_TRAIN[train_index], X_TRAIN[test_index]\n",
    "        y_train, y_test = Y_TRAIN[train_index], Y_TRAIN[test_index]\n",
    "        \n",
    "        #imp_mean.fit(x_train)\n",
    "        #x_train=imp_mean.transform(x_train)\n",
    "        \n",
    "        lr_clf = LogisticRegression(random_state = 0, solver=combination[\"solver\"] , \n",
    "                                    penalty=combination[\"penalty\"], C=combination[\"C\"], class_weight='balanced')\n",
    "        lr_clf.fit(x_train, y_train)\n",
    "        pred=lr_clf.predict(x_train)        \n",
    "        \n",
    "        #print('scoretrain:',roc_auc_score(y_train, pred))\n",
    "\n",
    "        #imp_mean.fit(X_TRAIN)\n",
    "        #x_test=imp_mean.transform(x_test)\n",
    "\n",
    "        pred=lr_clf.predict(x_test)\n",
    "        print('scoretest:',roc_auc_score(y_test, pred))\n",
    "        print(n)\n",
    "        score[n,i]=roc_auc_score(y_test, pred)\n",
    "        \n",
    "        i=i+1\n",
    "    \n",
    "    score_combi[n,0:1]=score[n,0:n_cv].mean()\n",
    "    print(\"score_combi\",score_combi[n])\n",
    "    \n",
    "    n=n+1\n",
    "    \n",
    "print(np.argmax(score_combi))\n",
    "bestparameters=combinations[np.argmax(score_combi)]\n",
    "print('bestparam:',bestparameters)    \n",
    "# une fois le modèle choisi\n",
    "# on entraine ce modèle sur le jeu complet et on score sur : evite de devoir choisir et permet aussi plus de robustesse\n",
    "#rf_clf = RandomForestClassifier(n_estimators=bestparameters[\"n_estimators\"],max_features=bestparameters[\"max_features\"],criterion=bestparameters[\"criterion\"], max_depth=combination[\"max_depth\"] , min_samples_leaf=combination[\"min_samples_leaf\"], class_weight='balanced')\n",
    "#rf_clf.fit(X_TRAIN, Y_TRAIN)\n",
    "#pred=rf_clf.predict(X_VALID)\n",
    "#print(roc_auc_score(Y_VALID, pred))\n",
    "\n",
    "# on recupere les hypermarametres et on reentraine le modele avec tout le jeu de données\n",
    "lr_clf = LogisticRegression(random_state = 0, solver=bestparameters[\"solver\"] , \n",
    "                                    penalty=bestparameters[\"penalty\"], C=bestparameters[\"C\"], class_weight='balanced')\n",
    "\n",
    "lr_clf = lr_clf.fit(X_TRAIN, Y_TRAIN)\n",
    "# on applique le modele au set de validation\n",
    "pred=lr_clf.predict(X_VALID)\n",
    "print(roc_auc_score(Y_VALID, pred))\n",
    "\n",
    "# on sauve le meilleur modele entrainé\n",
    "filename = 'model_lr_clf' + '.sav'\n",
    "joblib.dump(lr_clf, filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4c665c",
   "metadata": {},
   "source": [
    "#### Apllication du modele aux données de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362389ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BESTMODEL='model_' + str(np.argmax(score_combi)) + '.sav'\n",
    "# load the model from disk\n",
    "BESTMODEL='model_lr_clf.sav'\n",
    "\n",
    "loaded_model = joblib.load(BESTMODEL)\n",
    "\n",
    "\n",
    "pred=loaded_model.predict(X_VALID)\n",
    "print(roc_auc_score(Y_VALID, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345e8d0c",
   "metadata": {},
   "source": [
    "### Représentation des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fdd48c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c=confusion_matrix(Y_VALID,pred)\n",
    "c=c/c.astype(np.float).sum(axis=0)\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(c, annot=True, fmt='.2f')#, xticklabels=['0','1'], yticklabels==['0','1'])\n",
    "plt.ylabel('Réel')\n",
    "plt.xlabel('Prédit')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377cc33d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(loaded_model, X_VALID, Y_VALID)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828e532b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#explainer=shap.TreeExplainer(lr_clf)\n",
    "#values=explainer.shap_values(X_TRAIN)\n",
    "#shap.plots.waterfall(values)#beeswarm(values[0])#waterfall(values[0])\n",
    "#listfeat=df.columns.drop(['TARGET'])\n",
    "#shap.summary_plot(values,X_TRAIN, feature_names = listfeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a63dec8",
   "metadata": {},
   "source": [
    "# Application de la meme grid search manuelle pour XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101faf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN, X_VALID, Y_TRAIN, Y_VALID = train_test_split(X_train, Y_train, test_size=0.2, stratify=Y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4775fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "parameters = {\n",
    "        'min_child_weight': [5, 10],\n",
    "        'colsample_bytree': [0.6, 1.0],\n",
    "        'max_depth': [3, 5]\n",
    "        }\n",
    "\n",
    "keys = parameters.keys()\n",
    "values = (parameters[key] for key in keys)\n",
    "combinations = [dict(zip(keys, combination)) for combination in itertools.product(*values)]\n",
    "\n",
    "# creation d'une boucle de cross-validation\n",
    "#imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "score=np.empty((len(combinations),5)) # matrix de score cv\n",
    "score_combi=np.empty((len(combinations),1)) # matrice de score grid\n",
    "\n",
    "print(\"all combinations of hyperparameters=\",combinations)\n",
    "n_cv=2\n",
    "n=0\n",
    "for combination in tqdm_notebook(combinations):    \n",
    "    print(combination)\n",
    "    kf = KFold(n_splits=n_cv)\n",
    "    i=0\n",
    "    for train_index, test_index in kf.split(X_TRAIN):\n",
    "        x_train, x_test = X_TRAIN[train_index], X_TRAIN[test_index]\n",
    "        y_train, y_test = Y_TRAIN[train_index], Y_TRAIN[test_index]\n",
    "        \n",
    "        \n",
    "        #x_train, y_train = oversample.fit_resample(x_train, y_train) # pour l'application du smote\n",
    "        xgb_clf=XGBClassifier(min_child_weight=combination[\"min_child_weight\"],colsample_bytree=combination[\"colsample_bytree\"],max_depth=combination[\"max_depth\"], class_weight='balanced')#scale_pos_weight=scale_pos_weight_value)\n",
    "        xgb_clf.fit(x_train, y_train)\n",
    "        pred=xgb_clf.predict(x_train)\n",
    "        \n",
    "        #print('scoretrain:',roc_auc_score(y_train, pred))\n",
    "        pred=xgb_clf.predict(x_test)\n",
    "        print('scoretest:',roc_auc_score(y_test, pred))\n",
    "        print(n)\n",
    "        score[n,i]=roc_auc_score(y_test, pred)\n",
    "        i=i+1\n",
    "    score_combi[n,0:1]=score[n,0:n_cv].mean()\n",
    "    print(\"score_combi\",score_combi[n])\n",
    "    n=n+1\n",
    "    \n",
    "print(np.argmax(score_combi))\n",
    "bestparameters=combinations[np.argmax(score_combi)]\n",
    "print('bestparam:',bestparameters)    \n",
    "\n",
    "# on recupere les hypermarametres et on reentraine le modele avec tout le jeu de données d'ENTRAINEMENT\n",
    "xgb_clf = XGBClassifier(random_state = 0, min_child_weight=bestparameters[\"min_child_weight\"] , \n",
    "                                    colsample_bytree=bestparameters[\"colsample_bytree\"], max_depth=bestparameters[\"max_depth\"], class_weight='balanced')\n",
    "\n",
    "#X_TRAIN, Y_TRAIN = oversample.fit_resample(X_TRAIN, Y_TRAIN)\n",
    "xgb_clf=xgb_clf.fit(X_TRAIN, Y_TRAIN)\n",
    "# on applique le modele au set de validation\n",
    "pred=xgb_clf.predict(X_VALID)\n",
    "print(roc_auc_score(Y_VALID, pred))\n",
    "\n",
    "# on sauve le meilleur modele entrainé\n",
    "filename = 'model_xgb_clf' + '.sav'\n",
    "joblib.dump(xgb_clf, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a28abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "BESTMODEL='model_xgb_clf.sav'\n",
    "\n",
    "loaded_model = joblib.load(BESTMODEL)\n",
    "\n",
    "\n",
    "pred=loaded_model.predict(X_VALID)\n",
    "print(roc_auc_score(Y_VALID, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46774f76",
   "metadata": {},
   "source": [
    "## Représentation des résultats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed77d841",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=confusion_matrix(Y_VALID,pred)\n",
    "c=c/c.astype(np.float).sum(axis=0)\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(c, annot=True, fmt='.2f')#, xticklabels=['0','1'], yticklabels==['0','1'])\n",
    "plt.ylabel('Réel')\n",
    "plt.xlabel('Prédit')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41892344",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(loaded_model, X_VALID, Y_VALID)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b929a4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f489eeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer=shap.TreeExplainer(xgb_clf)\n",
    "values=explainer.shap_values(X_TRAIN)\n",
    "#shap.plots.waterfall(values)#beeswarm(values[0])#waterfall(values[0])\n",
    "listfeat=df.columns.drop(['TARGET'])\n",
    "shap.summary_plot(values,X_TRAIN, feature_names = listfeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264535ca",
   "metadata": {},
   "source": [
    "\n",
    "# Application de la meme grid search manuelle pour CatBoost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed637de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN, X_VALID, Y_TRAIN, Y_VALID = train_test_split(X_train, Y_train, test_size=0.2, stratify=Y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a9a2f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier \n",
    "\n",
    "#print('AUC on Training set:',cross_val_score(CatBoost_clf, X_TRAIN, Y_TRAIN, cv=3, scoring='roc_auc'))\n",
    "#print('AUC on Test set:',cross_val_score(CatBoost_clf, X_TEST, Y_TEST, cv=3, scoring='roc_auc'))\n",
    "#parameters = {\n",
    "#          'depth': [4, 8],\n",
    "#          'loss_function': ['Logloss', 'CrossEntropy'],\n",
    "#          'iterations': [100,500]#,'l2_leaf_reg': np.logspace(-20, 3),\n",
    "#         }\n",
    "#parameters = {'loss_function':'Logloss', # objective function\n",
    "#          'eval_metric':'AUC', # metric\n",
    "#          'verbose': 200, # output to stdout info about training process every 200 iterations\n",
    "#          'random_seed': SEED,\n",
    "#          'depth': [4, 8],\n",
    "#          'iterations': [50,100]\n",
    "#         }\n",
    "parameters = {'learning_rate': [0.4, 0.6],\n",
    "        'depth': [2, 10],\n",
    "        'l2_leaf_reg': [2,4,6]}\n",
    "\n",
    "keys = parameters.keys()\n",
    "values = (parameters[key] for key in keys)\n",
    "combinations = [dict(zip(keys, combination)) for combination in itertools.product(*values)]\n",
    "\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mean.fit(X_TRAIN) # imputer\n",
    "X_TRAIN=imp_mean.transform(X_TRAIN)\n",
    "X_VALID=imp_mean.transform(X_VALID)\n",
    "# creation d'une boucle de cross-validation\n",
    "#oversample = SMOTE()\n",
    "#imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "score=np.empty((len(combinations),5))\n",
    "score_combi=np.empty((len(combinations),1))\n",
    "\n",
    "print(\"all combinations of hyperparameters=\",combinations)\n",
    "n_cv=3\n",
    "n=0\n",
    "for combination in tqdm_notebook(combinations):    \n",
    "    print(combination)\n",
    "    kf = KFold(n_splits=n_cv)\n",
    "    i=0\n",
    "    for train_index, test_index in kf.split(X_TRAIN):\n",
    "        x_train, x_test = X_TRAIN[train_index], X_TRAIN[test_index]\n",
    "        y_train, y_test = Y_TRAIN[train_index], Y_TRAIN[test_index]\n",
    "        \n",
    "        x_train, y_train = oversample.fit_resample(x_train, y_train)\n",
    "        \n",
    "        cat_clf=CatBoostClassifier(learning_rate=combination[\"learning_rate\"],depth=combination[\"depth\"],l2_leaf_reg=combination[\"l2_leaf_reg\"],iterations=50,eval_metric='AUC',verbose=False)#, class_weight='balanced')#scale_pos_weight=scale_pos_weight_value)\n",
    "        cat_clf.fit(x_train, y_train)\n",
    "        pred=cat_clf.predict(x_train)\n",
    "        \n",
    "        #print('scoretrain:',roc_auc_score(y_train, pred))\n",
    "\n",
    "        pred=cat_clf.predict(x_test)\n",
    "        print('scoretest:',roc_auc_score(y_test, pred))\n",
    "        print(n)\n",
    "        score[n,i]=roc_auc_score(y_test, pred)\n",
    "        i=i+1\n",
    "    score_combi[n,0:1]=score[n,0:n_cv].mean()\n",
    "    print(\"score_combi\",score_combi[n])\n",
    "    n=n+1\n",
    "    \n",
    "print(np.argmax(score_combi))\n",
    "bestparameters=combinations[np.argmax(score_combi)]\n",
    "print('bestparam:',bestparameters)    \n",
    "\n",
    "# on recupere les hypermarametres et on reentraine le modele avec tout le jeu de données d'ENTRAINEMENT\n",
    "cat_clf = CatBoostClassifier(random_state = 0, learning_rate=bestparameters[\"learning_rate\"] , \n",
    "                                    depth=bestparameters[\"depth\"], l2_leaf_reg=bestparameters[\"l2_leaf_reg\"],iterations=50,eval_metric='AUC',verbose=False)#, class_weight='balanced')\n",
    "X_TRAIN, Y_TRAIN = oversample.fit_resample(X_TRAIN, Y_TRAIN)\n",
    "cat_clf = cat_clf.fit(X_TRAIN, Y_TRAIN)\n",
    "# on applique le modele au set de validation\n",
    "pred=cat_clf.predict(X_VALID)\n",
    "print(roc_auc_score(Y_VALID, pred))\n",
    "\n",
    "# on sauve le meilleur modele entrainé\n",
    "filename = 'model_cat_clf' + '.sav'\n",
    "joblib.dump(cat_clf, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4d8a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "BESTMODEL='model_cat_clf.sav'\n",
    "\n",
    "loaded_model = joblib.load(BESTMODEL)\n",
    "\n",
    "\n",
    "pred=loaded_model.predict(X_VALID)\n",
    "print(roc_auc_score(Y_VALID, pred))\n",
    "print(roc_auc_score(Y_VALID, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc585934",
   "metadata": {},
   "source": [
    "## Représentation des résultats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417388f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=confusion_matrix(Y_VALID,pred)\n",
    "c=c/c.astype(np.float).sum(axis=0)\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(c, annot=True, fmt='.2f')#, xticklabels=['0','1'], yticklabels==['0','1'])\n",
    "plt.ylabel('Réel')\n",
    "plt.xlabel('Prédit')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73070c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(loaded_model, X_VALID, Y_VALID)\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bc3227",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer=shap.TreeExplainer(cat_clf)\n",
    "values=explainer.shap_values(X_TRAIN)\n",
    "#shap.plots.waterfall(values)#beeswarm(values[0])#waterfall(values[0])\n",
    "listfeat=df.columns.drop(['TARGET'])\n",
    "shap.summary_plot(values,X_TRAIN, feature_names = listfeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce214d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ffc7eab",
   "metadata": {},
   "source": [
    "inspiré de :\n",
    "https://www.kaggle.com/code/shailaja4247/tackle-any-credit-risk-analysis-problem-homecredit/notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
